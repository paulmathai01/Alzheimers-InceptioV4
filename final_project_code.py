# -*- coding: utf-8 -*-
"""Final Project code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yNzwWinO6p0azsRP6IEOVlZNQoe2cvQD
"""

!git clone https://github.com/paulmathai01/al_data.git

ls

import numpy as np
import os
from PIL import Image
from matplotlib import pyplot as plt
from keras.utils.data_utils import Sequence
from imblearn.over_sampling import RandomOverSampler  # conda install -c glemaitre imbalanced-learn
from keras.utils import np_utils
from skimage.exposure import equalize_adapthist as eq_hist

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, concatenate, Reshape, Activation
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K
from sklearn.metrics import log_loss
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import optimizers
from tensorflow.keras.layers import concatenate
from tensorflow.keras import regularizers
from tensorflow.keras import initializers

#########################################################################################
#                            Data Pre-processing                                        #
#########################################################################################
TRAIN_DIR = 'al_data/data/train/'
TEST_DIR = 'al_data/data/test/'
IMAGE_SIZE = 299
CLASSES = [
    'NonDemented',
    'VeryMildDemented',
    'MildDemented',
    'ModerateDemented',
]

train_images = {}
test_images = {}


for label in CLASSES:
    train_images[label] = []
    test_images[label] = []

for label in CLASSES:
    for image in os.listdir(TRAIN_DIR + label):
        im = Image.open(TRAIN_DIR + label + '/' + image).convert('L')
        train_images[label].append(im.resize((IMAGE_SIZE, IMAGE_SIZE)))
        
    for image in os.listdir(TEST_DIR + label):
        im = Image.open(TEST_DIR + label + '/' + image).convert('L')
        test_images[label].append(im.resize((IMAGE_SIZE, IMAGE_SIZE)))

################### Visualize a sample of images #####################################
plt.figure(1, figsize=(20, 4))
i = 1
for label in CLASSES:
    avg_pic = np.zeros((IMAGE_SIZE, IMAGE_SIZE))
    for pic in train_images[label] + test_images[label]:
        avg_pic += np.array(pic)
    avg_pic = avg_pic / (len(train_images[label]) + len(test_images[label]))
    plt.subplot(1, 4, i)
    i += 1
    plt.imshow(avg_pic, cmap='gray')
    plt.xlabel('%s average\ntotally %d/%d pics' % (label, len(train_images[label]), len(test_images[label])))
plt.show()
 


class_weight = {}
max_classes = len(test_images['NonDemented']) / 100
for i, klass in enumerate(CLASSES):
    class_weight[i] = max_classes / len(test_images[klass])
class_weight

################## Split data #######################################################

def equalize(im):
    return eq_hist(np.array(im), clip_limit=0.03)

train_data = np.array([equalize(i) for i in train_images[CLASSES[0]]])
train_labels = np.zeros((len(train_images[CLASSES[0]]), 1))
for ind, klass in enumerate(CLASSES[1:], start=1):
    klass_arr = np.array([equalize(i) for i in train_images[klass]])
    train_data = np.concatenate([train_data, klass_arr], axis=0)
    
    labels_arr = np.ones((len(train_images[klass]), 1)) * ind
    train_labels = np.concatenate([train_labels, labels_arr], axis=0)

test_data = np.array([equalize(i) for i in test_images[CLASSES[0]]])
test_labels = np.zeros((len(test_images[CLASSES[0]]), 1))
for ind, klass in enumerate(CLASSES[1:], start=1):
    klass_arr = np.array([equalize(i) for i in test_images[klass]])
    test_data = np.concatenate([test_data, klass_arr], axis=0)
    
    labels_arr = np.ones((len(test_images[klass]), 1)) * ind
    test_labels = np.concatenate([test_labels, labels_arr], axis=0)

    
train_data = train_data.reshape((-1, IMAGE_SIZE, IMAGE_SIZE, 1))
test_data = test_data.reshape((-1, IMAGE_SIZE, IMAGE_SIZE, 1))

train_labels = np_utils.to_categorical(train_labels)
test_labels = np_utils.to_categorical(test_labels)

train_data.shape, train_labels.shape, test_data.shape, test_labels.shape

def conv2d_bn(x, nb_filter, num_row, num_col,
              padding='same', strides=(1, 1), use_bias=False):
    
    if K.image_data_format() == 'channels_first':
        channel_axis = 1
    else:
        channel_axis = -1
    x = Convolution2D(nb_filter, (num_row, num_col),
                      strides=strides,
                      padding=padding,
                      use_bias=use_bias,
                      kernel_regularizer=regularizers.l2(0.00004),
                      kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(x)
    x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)
    x = Activation('relu')(x)
    return x

################## 4 x Inception-A ###############################
def block_inception_a(input):
    if K.image_data_format() == 'channels_first':
        channel_axis = 1
    else:
        channel_axis = -1

    branch_0 = conv2d_bn(input, 96, 1, 1)

    branch_1 = conv2d_bn(input, 64, 1, 1)
    branch_1 = conv2d_bn(branch_1, 96, 3, 3)

    branch_2 = conv2d_bn(input, 64, 1, 1)
    branch_2 = conv2d_bn(branch_2, 96, 3, 3)
    branch_2 = conv2d_bn(branch_2, 96, 3, 3)

    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)
    branch_3 = conv2d_bn(branch_3, 96, 1, 1)

    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)
    return x

################## Reduction-A ###############################

def block_reduction_a(input):
    if K.image_data_format() == 'channels_first':
        channel_axis = 1
    else:
        channel_axis = -1

    branch_0 = conv2d_bn(input, 384, 3, 3, strides=(2,2), padding='valid')

    branch_1 = conv2d_bn(input, 192, 1, 1)
    branch_1 = conv2d_bn(branch_1, 224, 3, 3)
    branch_1 = conv2d_bn(branch_1, 256, 3, 3, strides=(2,2), padding='valid')

    branch_2 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(input)

    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)
    return x

################## 7 x Inception-B ###############################
def block_inception_b(input):
    if K.image_data_format() == 'channels_first':
        channel_axis = 1
    else:
        channel_axis = -1

    branch_0 = conv2d_bn(input, 384, 1, 1)

    branch_1 = conv2d_bn(input, 192, 1, 1)
    branch_1 = conv2d_bn(branch_1, 224, 1, 7)
    branch_1 = conv2d_bn(branch_1, 256, 7, 1)

    branch_2 = conv2d_bn(input, 192, 1, 1)
    branch_2 = conv2d_bn(branch_2, 192, 7, 1)
    branch_2 = conv2d_bn(branch_2, 224, 1, 7)
    branch_2 = conv2d_bn(branch_2, 224, 7, 1)
    branch_2 = conv2d_bn(branch_2, 256, 1, 7)

    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)
    branch_3 = conv2d_bn(branch_3, 128, 1, 1)

    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)
    return x

################## Reduction-B ###############################
def block_reduction_b(input):
    if K.image_data_format() == 'channels_first':
        channel_axis = 1
    else:
        channel_axis = -1

    branch_0 = conv2d_bn(input, 192, 1, 1)
    branch_0 = conv2d_bn(branch_0, 192, 3, 3, strides=(2, 2), padding='valid')

    branch_1 = conv2d_bn(input, 256, 1, 1)
    branch_1 = conv2d_bn(branch_1, 256, 1, 7)
    branch_1 = conv2d_bn(branch_1, 320, 7, 1)
    branch_1 = conv2d_bn(branch_1, 320, 3, 3, strides=(2,2), padding='valid')

    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input)

    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)
    return x

################## 3 x In

def block_inception_c(input):
    if K.image_data_format() == 'channels_first':
        channel_axis = 1
    else:
        channel_axis = -1

    branch_0 = conv2d_bn(input, 256, 1, 1)

    branch_1 = conv2d_bn(input, 384, 1, 1)
    branch_10 = conv2d_bn(branch_1, 256, 1, 3)
    branch_11 = conv2d_bn(branch_1, 256, 3, 1)
    branch_1 = concatenate([branch_10, branch_11], axis=channel_axis)


    branch_2 = conv2d_bn(input, 384, 1, 1)
    branch_2 = conv2d_bn(branch_2, 448, 3, 1)
    branch_2 = conv2d_bn(branch_2, 512, 1, 3)
    branch_20 = conv2d_bn(branch_2, 256, 1, 3)
    branch_21 = conv2d_bn(branch_2, 256, 3, 1)
    branch_2 = concatenate([branch_20, branch_21], axis=channel_axis)

    branch_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input)
    branch_3 = conv2d_bn(branch_3, 256, 1, 1)

    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)
    return x

def inception_v4_base(input):
    if K.image_data_format() == 'channels_first':
        channel_axis = 1
    else:
        channel_axis = -1

    # Input Shape is 299 x 299 x 3 (th) or 3 x 299 x 299 (th)
    net = conv2d_bn(input, 32, 3, 3, strides=(2,2), padding='valid')
    net = conv2d_bn(net, 32, 3, 3, padding='valid')
    net = conv2d_bn(net, 64, 3, 3)

    branch_0 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)

    branch_1 = conv2d_bn(net, 96, 3, 3, strides=(2,2), padding='valid')

    net = concatenate([branch_0, branch_1], axis=channel_axis)

    branch_0 = conv2d_bn(net, 64, 1, 1)
    branch_0 = conv2d_bn(branch_0, 96, 3, 3, padding='valid')

    branch_1 = conv2d_bn(net, 64, 1, 1)
    branch_1 = conv2d_bn(branch_1, 64, 1, 7)
    branch_1 = conv2d_bn(branch_1, 64, 7, 1)
    branch_1 = conv2d_bn(branch_1, 96, 3, 3, padding='valid')

    net = concatenate([branch_0, branch_1], axis=channel_axis)

    branch_0 = conv2d_bn(net, 192, 3, 3, strides=(2,2), padding='valid')
    branch_1 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)

    net = concatenate([branch_0, branch_1], axis=channel_axis)

    # 35 x 35 x 384
    # 4 x Inception-A blocks
    for idx in range(4):
    	net = block_inception_a(net)

    # 35 x 35 x 384
    # Reduction-A block
    net = block_reduction_a(net)

    # 17 x 17 x 1024
    # 7 x Inception-B blocks
    for idx in range(7):
    	net = block_inception_b(net)

    # 17 x 17 x 1024
    # Reduction-B block
    net = block_reduction_b(net)

    # 8 x 8 x 1536
    # 3 x Inception-C blocks
    for idx in range(3):
    	net = block_inception_c(net)

    return net

def inception_v4(num_classes, dropout_keep_prob, weights, include_top):

    # Input Shape is 299 x 299 x 3 (tf) or 3 x 299 x 299 (th)
    if K.image_data_format() == 'channels_first':
        inputs = Input((3, 299, 299))
    else:
        inputs = Input((299, 299, 3))

    # Make inception base
    x = inception_v4_base(inputs)


    # Final pooling and prediction
    if include_top:
        # 1 x 1 x 1536
        x = AveragePooling2D((8,8), padding='valid')(x)
        x = Dropout(0.2)(x)
        #x = Flatten()(x)
        # 1536
        x = Dense(units=num_classes, activation='softmax')(x)

    model = Model(inputs, x, name='inception_v4')
    return model

if __name__ == '__main__':

    # dimensions of our images.
    img_width, img_height = 299, 299

    nb_train_samples = train_data.shape[0]
    nb_validation_samples = test_data.shape[0]
    epochs = 100
    batch_size = 8 #10 #40
    channel = 3
    num_classes = 4

    train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

    test_datagen = ImageDataGenerator(rescale=1./255)

    
    train_generator = train_datagen.flow_from_directory(
        TRAIN_DIR,
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='binary')

    validation_generator = test_datagen.flow_from_directory(
        TEST_DIR,
        target_size=(img_width, img_height),
        batch_size=batch_size,
    class_mode='binary')

    # Load our model
    model = inception_v4(img_height, img_width, channel, num_classes)
    model.compile(loss = 'sparse_categorical_crossentropy')
    #model.fit(train_data,train_labels,epochs=epochs, batch_size=batch_size)
    model.fit_generator(
        train_generator,
        steps_per_epoch=nb_train_samples // batch_size,
        epochs=epochs,
        validation_data = validation_generator,
        validation_steps=nb_validation_samples // batch_size)
    model.save('InceptionV4_model_04.h5')

TEST2_DIR = 'al_data/test2/'
test_datagen2 = ImageDataGenerator(rescale=1./255)


test_generator = test_datagen2.flow_from_directory(
  TEST2_DIR,
  target_size=(img_width, img_height),
  batch_size=batch_size,
  class_mode='binary')

test_generator.samples

# Make predictions
    predictions_valid = model.predict_generator(test_generator, verbose=1)

# Cross-entropy loss score
    score = log_loss(test_labels, predictions_valid)

y_pred = np.argmax(predictions_valid, axis=1)
print('Confusion Matrix')
print(confusion_matrix(validation_generator.classes, y_pred))
print('Classification Report')
print(classification_report(validation_generator.classes, y_pred, target_names=CLASSES))